# Telegraf Configuration
#
# Telegraf is entirely plugin driven. All metrics are gathered from the
# declared inputs, and sent to the declared outputs.
#
# Plugins must be declared in here to be active.
# To deactivate a plugin, comment out the name and any variables.
#
# Use 'telegraf -config telegraf.conf -test' to see what metrics a config
# file would generate.
#
# Environment variables can be used anywhere in this config file, simply surround
# them with ${}. For strings the variable must be within quotes (ie, "${STR_VAR}"),
# for numbers and booleans they should be plain (ie, ${INT_VAR}, ${BOOL_VAR})


# Global tags can be specified here in key="value" format.
[global_tags]
  # dc = "us-east-1" # will tag all metrics with dc=us-east-1
  # rack = "1a"
  ## Environment variables can be used as tags, and throughout the config file
  # user = "$USER"
  # env="dev"

# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "10s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 5000

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Collection offset is used to shift the collection by the given amount.
  ## This can be be used to avoid many plugins querying constraint devices
  ## at the same time by manually scheduling them in time.
  # collection_offset = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "2s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## Collected metrics are rounded to the precision specified. Precision is
  ## specified as an interval with an integer + unit (e.g. 0s, 10ms, 2us, 4s).
  ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
  ##
  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s:
  ##   ie, when interval = "10s", precision will be "1s"
  ##       when interval = "250ms", precision will be "1ms"
  ##
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  precision = "0s"

  ## Pick a timezone to use when logging or type 'local' for local time.
  ## Example: America/Chicago
  # log_with_timezone = ""

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = true

###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################


# Configuration for sending metrics to InfluxDB
[[outputs.influxdb_v2]]
  ## The full HTTP or UDP URL for your InfluxDB instance.
  ##
  ## Multiple URLs can be specified for a single cluster, only ONE of the
  ## urls will be written to each interval.
  # urls = ["unix:///var/run/influxdb.sock"]
  # urls = ["udp://127.0.0.1:8089"]
  # urls = ["http://127.0.0.1:8086"]
    urls = ["http://${DOCKER_INFLUXDB_INIT_HOST}:${DOCKER_INFLUXDB_INIT_PORT}"]

    ## Token for authentication.
    token = "${DOCKER_INFLUX_TOKEN}"

    ## Organization is the name of the organization you wish to write to; must exist.
    organization = "${DOCKER_INFLUXDB_INIT_ORG}"

    ## Destination bucket to write into.
    bucket = "${DOCKER_INFLUXDB_TELEGRAF_BUCKET}"
    
    namepass = ["mem", 
                "processes", 
                "swap", 
                "system", 
                "disk", 
                "diskio", 
                "kernel", 
                "net", 
                "netstat", 
                "nstat", 
                "net_response", 
                "net_response_listener", 
                "net_response_listener_summary", 
                "net_response_summary", 
                "net_response_timeouts", 
                "net_response_timeouts_summary", 
                "net_response_timeouts_total", 
                "net_response_total", 
                "net_response_udp", 
                "net_response_udp_summary", 
                "net_response_udp_total", 
                "netstat", 
                "nstat", 
                "nstat_udp", 
                "nstat_udp_summary", 
                "nstat_udp_total", 
                "nstat_summary", 
                "nstat_total", 
                "netstat_summary", 
                "netstat_total", 
                "net_response_udp_listener", 
                "net_response_udp_listener_summary", 
                "net_response_udp_listener_total", 
                "net_response_listener", 
                "net_response_listener_summary", 
                "net_response_listener_total", 
                "net_response_timeouts_listener", 
                "net_response_timeouts_listener_summary", 
                "net_response_timeouts_listener_total",]


#[[outputs.influxdb_v2]]
#  urls = ["http://${DOCKER_INFLUXDB_INIT_HOST}:${DOCKER_INFLUXDB_INIT_PORT}"]
#  token = "$DOCKER_INFLUXDB_INIT_ADMIN_TOKEN"
#  organization = "$DOCKER_INFLUXDB_INIT_ORG"
#  bucket = "mqtt_real_format"
#  namepass = ["mqtt_real_format"]

#[[outputs.kafka]]
#  brokers = ["${KAFKA_HOST}:${KAFKA_PORT}"]
#  topic = "measures_formated"
#  client_id = "KafkaTelegraf"
#  namepass = ["mqtt_real_format"]
#  data_format = "json"

#[[outputs.kafka]]
#  brokers = ["${KAFKA_HOST}:${KAFKA_PORT}"]
#  topic = "testing_kafka_telegraf"
#  client_id = "KafkaTelegrafTesting"
#  namepass = ["testing_kafka_telegraf"]
#  data_format = "json"

[[outputs.influxdb_v2]]
  urls = ["http://${DOCKER_INFLUXDB_INIT_HOST}:${DOCKER_INFLUXDB_INIT_PORT}"]
  
  token = "${DOCKER_INFLUX_TOKEN}"
  organization = "${DOCKER_INFLUXDB_INIT_ORG}"
  bucket = "${DOCKER_INFLUXDB_INIT_BUCKET}"
  namepass = ["measures"]

###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################


# Read metrics about cpu usage
[[inputs.cpu]]
  percpu = true
  totalcpu = true
  collect_cpu_time = false
  report_active = false
  core_tags = false


# Read metrics about disk usage by mount point
[[inputs.disk]]
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]

[[inputs.diskio]]

[[inputs.kernel]]

[[inputs.mem]]

[[inputs.processes]]

[[inputs.swap]]

[[inputs.system]]

#[[inputs.kafka_consumer]]
#   ## Kafka brokers.
#    brokers = ["${KAFKA_HOST}:${KAFKA_PORT}"]
#    name_override = "example_users_consumer"
#    topics = ["example_avro"]
#    consumer_group = "example_users_consumers"
#    max_message_len = 1000000
#    data_format = "json"

#https://github.com/influxdata/telegraf/blob/release-1.25/plugins/inputs/kafka_consumer/README.md
[[inputs.kafka_consumer]]
#   ## Kafka brokers.
    brokers = ["${KAFKA_HOST}:${KAFKA_PORT}"]
    name_override = "measures"
    topics = ["${KAFKA_INFLUXDB_TOPIC}"] ## Topics to consume.

    max_message_len = 1000000
    consumer_group = "sensors_kafka_consumer"

    #offset = "newest"
    offset = "oldest"
    data_format = "json"

    tag_keys = ["equipmentId", "tags*"]
    json_name_key = "equipmentId"

    json_time_key="timestamp"
    #json_time_format="unix"
    json_time_format="2006-01-02T15:04:05Z07:00"
    #json_timestamp_units = "1ms"
    #json_string_fields = ["measures_connection_id", "measures_received_at"]
    json_string_fields = ["measures_connection_id"]

    [[processors.regex]]
      #namepass = ["mqtt_real_format"]
      [[processors.regex.tag_rename]]
        key = "tags"
        pattern = "(tags_)(.*)"
        replacement = "$2"
      [[processors.regex.field_rename]]
        key = "measures"
        pattern = "(measures_)(.*)"
        replacement = "$2"


#[[inputs.mqtt_consumer]]
#
## Example
## Topic: sensors/ABCD12
## {"sensor_id": some_id, "tags": {"_tag1": "UP","_tag2": "RUNNING"},"measures":{"measure1":1,"measure2":2},"timestamp": unix_timestamp1, # optional}
## https://docs.influxdata.com/telegraf/v1.24/data_formats/input/json/
#
#  servers = ["tcp://mosquitto:1883"]
#  name_override = "mqtt_real_format"
#  topics = ["sensors/#",]
#  qos = 1
#  # connection_timeout = "60s"
#  # persistent_session = false
#  username = "hass"
#  password = "admin"
#  client_id = "telegraf.client"
#
#  data_format = "json"
#
#  json_name_key = "sensor_id"
#
#  tag_keys = ["sensor_id"]
#
#  [[processors.regex]]
#    #namepass = ["mqtt_real_format"]
#    [[processors.regex.tag_rename]]
#      key = "tags"
#      pattern = "(tags_)(.*)"
#      replacement = "$2"
#    [[processors.regex.field_rename]]
#      key = "measures"
#      pattern = "(measures_)(.*)"
#      replacement = "$2"

  #json_time_key = "timestamp"
  #json_time_format = "2006-01-02T15:04:05Z07:00"

  ## Time key is the key containing the time that should be used to create the
  ## metric. If the key does not exist, then the time of the metric will be set
  ## json_time_key = "timestamp"
  ## Time format is the time layout that should be used to interprete the
  ## json_time_key.  The time must be `unix`, `unix_ms` or a time in the
  ## "reference time".
  ##   ex: json_time_format = "Mon Jan 2 15:04:05 -0700 MST 2006"
  ##       json_time_format = "2006-01-02T15:04:05Z07:00"
  ##       json_time_format = "unix"
  ##       json_time_format = "unix_ms"
  ## json_time_format = "unix_ms"

  ## Query is a GJSON path that specifies a specific chunk of JSON to be
  ## parsed, if not specified the whole document will be parsed.
  ##
  ## GJSON query paths are described here:
  ##   https://github.com/tidwall/gjson#path-syntax
  ## json_query = ""
  ## json_string_fields = ["measures_*"]
  
  #[[inputs.mqtt_consumer.topic_parsing]]
  #  topic = "sensors/+"
  #  tags = "_/sensor_id"
#  [[inputs.mqtt_consumer.json_v2]]
#      [[inputs.mqtt_consumer.json_v2.tag]]
#          path = "measure_name"
#      [[inputs.mqtt_consumer.json_v2.field]]
#          path = "measure_value"



